# How the ScriptToDoc Agent Works: A 7-Stage Intelligent Pipeline

The ScriptToDoc agent transforms meeting transcripts into professional training documents through a sophisticated **7-stage pipeline** that combines AI-powered content generation with intelligent knowledge integration.

---

## Pipeline Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ScriptToDoc 7-Stage Pipeline                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Stage 1: LOAD & VALIDATE
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Input â†’ Validation â†’ Configuration                                 â”‚
â”‚  â€¢ Upload transcript (.txt, .pdf)                                        â”‚
â”‚  â€¢ Provide knowledge URLs (optional)                                     â”‚
â”‚  â€¢ Configure: tone, audience, target_steps, document_title              â”‚
â”‚  â€¢ Validate file format and size                                         â”‚
â”‚  [STATUS: User Approval Required] âœ‹                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚ User clicks "Generate"
                                     â†“
Stage 2: FETCH KNOWLEDGE
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Knowledge Fetcher: Parallel URL Retrieval                               â”‚
â”‚  â€¢ Fetch content from provided URLs (web, PDF, docs)                    â”‚
â”‚  â€¢ Extract up to 100k chars per source                                   â”‚
â”‚  â€¢ Cache for 24 hours (fast re-runs)                                     â”‚
â”‚  â€¢ Handle errors gracefully (continue if some fail)                      â”‚
â”‚                                                                           â”‚
â”‚  Output: List of knowledge sources with content + metadata               â”‚
â”‚  Tags: [FETCHED], [ERROR], [CACHED]                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â†“
Stage 3: CLEAN & TOKENIZE
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Transcript Cleaner: Text Normalization                                  â”‚
â”‚  â€¢ Sentence tokenization (NLTK)                                          â”‚
â”‚  â€¢ Normalize whitespace, punctuation                                     â”‚
â”‚  â€¢ Remove artifacts, fix formatting                                      â”‚
â”‚  â€¢ Build sentence catalog for source matching                            â”‚
â”‚                                                                           â”‚
â”‚  Output: Clean sentence list (used for source grounding)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â†“
Stage 4: SEMANTIC CHUNKING
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Transcript Chunker: Intelligent Splitting                               â”‚
â”‚  â€¢ Split into N chunks (where N = target_steps)                          â”‚
â”‚  â€¢ Ensure 6-12 sentences per chunk                                       â”‚
â”‚  â€¢ Maintain semantic continuity (no mid-topic splits)                    â”‚
â”‚  â€¢ Balance chunk sizes (no tiny/huge chunks)                             â”‚
â”‚                                                                           â”‚
â”‚  Output: N focused chunks (1 chunk â†’ 1 training step)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â†“
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚  FOR EACH CHUNK:   â”‚
                            â”‚  (Parallel Loop)   â”‚
                            â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â†“
Stage 5: GENERATE STEPS (The Core Loop)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ”„ ITERATIVE PROCESS FOR EACH CHUNK (N iterations)                     â”‚
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 5.1 SEMANTIC SEARCH (Knowledge Matching)                         â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  Knowledge Fetcher â†’ find_relevant_excerpts()                    â”‚   â”‚
â”‚  â”‚  â€¢ Encode chunk using sentence-transformers (all-MiniLM-L6-v2)  â”‚   â”‚
â”‚  â”‚  â€¢ Split knowledge sources into 500-char overlapping excerpts   â”‚   â”‚
â”‚  â”‚  â€¢ Calculate cosine similarity: chunk â†” each excerpt            â”‚   â”‚
â”‚  â”‚  â€¢ Filter: keep only excerpts with similarity > 0.1             â”‚   â”‚
â”‚  â”‚  â€¢ Rank by relevance score (0.0-1.0)                            â”‚   â”‚
â”‚  â”‚  â€¢ Select top 5 excerpts overall                                â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  Output: Top 5 relevant excerpts with scores                    â”‚   â”‚
â”‚  â”‚  Tags: [SEMANTIC_MATCH], [HIGH_RELEVANCE], [FILTERED]          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                 â†“                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 5.2 PROMPT CONSTRUCTION                                          â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  Azure OpenAI Client â†’ _build_chunk_prompt()                    â”‚   â”‚
â”‚  â”‚  â€¢ Inject transcript chunk (6-12 sentences)                      â”‚   â”‚
â”‚  â”‚  â€¢ Inject top 5 relevant knowledge excerpts with scores         â”‚   â”‚
â”‚  â”‚  â€¢ Add grounding instructions:                                   â”‚   â”‚
â”‚  â”‚    âœ“ Quote transcript directly (exact terminology)              â”‚   â”‚
â”‚  â”‚    âœ“ Enhance with knowledge context                             â”‚   â”‚
â”‚  â”‚    âœ“ Add technical depth from sources                           â”‚   â”‚
â”‚  â”‚    âœ— Don't contradict transcript                                â”‚   â”‚
â”‚  â”‚    âœ— Don't replace transcript content                           â”‚   â”‚
â”‚  â”‚  â€¢ Set tone, audience, step index                               â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  Prompt Structure:                                               â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚ CREATE ONE TRAINING STEP (Step N of M)                   â”‚  â”‚   â”‚
â”‚  â”‚  â”‚                                                           â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ TRANSCRIPT CHUNK:                                         â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ [6-12 focused sentences from transcript]                 â”‚  â”‚   â”‚
â”‚  â”‚  â”‚                                                           â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ === RELEVANT KNOWLEDGE SOURCES ===                       â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ ğŸ“š MOST RELEVANT EXCERPTS (sorted by relevance):        â”‚  â”‚   â”‚
â”‚  â”‚  â”‚                                                           â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ [Excerpt 1] Azure Deployment Guide (Relevance: 0.87)    â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ URL: https://learn.microsoft.com/...                     â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ Content: When configuring deployment capacity...        â”‚  â”‚   â”‚
â”‚  â”‚  â”‚                                                           â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ [Excerpt 2] Best Practices (Relevance: 0.72)            â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ URL: https://docs.azure.com/...                          â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ Content: Token capacity affects throughput...            â”‚  â”‚   â”‚
â”‚  â”‚  â”‚                                                           â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ ğŸ“ INSTRUCTIONS FOR USING KNOWLEDGE:                     â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ âœ“ DO: Use knowledge for technical depth                 â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ âœ— DON'T: Replace transcript content                     â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                 â†“                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 5.3 LLM GENERATION                                               â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  Azure OpenAI (gpt-4o) or OpenAI (gpt-4o-mini fallback)        â”‚   â”‚
â”‚  â”‚  â€¢ Temperature: 0.2 (focused, consistent)                       â”‚   â”‚
â”‚  â”‚  â€¢ Max tokens: 1000 (one step)                                  â”‚   â”‚
â”‚  â”‚  â€¢ Top-p: 0.85 (slightly lower for precision)                  â”‚   â”‚
â”‚  â”‚  â€¢ Timeout: 60s                                                 â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  Output: ONE training step                                      â”‚   â”‚
â”‚  â”‚  {                                                               â”‚   â”‚
â”‚  â”‚    "title": "Configure Azure OpenAI Deployment Settings",       â”‚   â”‚
â”‚  â”‚    "summary": "Navigate to Deployments section...",             â”‚   â”‚
â”‚  â”‚    "details": "In the Azure Portal, access... Microsoft         â”‚   â”‚
â”‚  â”‚                recommends 10K TPM for production...",            â”‚   â”‚
â”‚  â”‚    "actions": [                                                  â”‚   â”‚
â”‚  â”‚      "Navigate to Deployments section in Azure Portal",         â”‚   â”‚
â”‚  â”‚      "Click Create to start new deployment",                    â”‚   â”‚
â”‚  â”‚      "Set capacity to 10K tokens per minute",                   â”‚   â”‚
â”‚  â”‚      "Select gpt-4o model from available models",               â”‚   â”‚
â”‚  â”‚      "Choose region closest to users for optimal latency"       â”‚   â”‚
â”‚  â”‚    ]                                                             â”‚   â”‚
â”‚  â”‚  }                                                               â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  Token Usage: ~650 tokens (input + output)                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                           â”‚
â”‚  Total Steps Generated: N steps (one per chunk)                          â”‚
â”‚  Total Tokens: ~650 Ã— N tokens                                           â”‚
â”‚  Processing Time: ~4-6 seconds per step                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â†“
Stage 6: VALIDATE & SCORE (Quality Gate)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ” CRITIQUE LOOP FOR EACH GENERATED STEP                                â”‚
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 6.1 SOURCE MATCHING                                              â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  Source Reference Manager â†’ build_step_sources()                â”‚   â”‚
â”‚  â”‚  â€¢ Search transcript for sentences matching the step            â”‚   â”‚
â”‚  â”‚  â€¢ Use hybrid scoring:                                           â”‚   â”‚
â”‚  â”‚    - 50% word overlap (Jaccard similarity)                      â”‚   â”‚
â”‚  â”‚    - 50% semantic similarity (sentence-transformers)            â”‚   â”‚
â”‚  â”‚  â€¢ Find top 5 matching transcript sentences                     â”‚   â”‚
â”‚  â”‚  â€¢ Match knowledge sources cited in step                         â”‚   â”‚
â”‚  â”‚  â€¢ Track source usage (which URLs were helpful)                 â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  Output: Sources per step                                        â”‚   â”‚
â”‚  â”‚  â€¢ Transcript sources: [3 sentences, avg confidence: 0.64]      â”‚   â”‚
â”‚  â”‚  â€¢ Knowledge sources: [2 URLs cited]                            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                 â†“                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 6.2 CONFIDENCE CALCULATION                                       â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  calculate_confidence() - Multi-factor scoring                  â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  Base Score (weighted average of top 3 sources):                â”‚   â”‚
â”‚  â”‚  â€¢ Source 1: 0.68 Ã— 50%                                         â”‚   â”‚
â”‚  â”‚  â€¢ Source 2: 0.64 Ã— 30%                                         â”‚   â”‚
â”‚  â”‚  â€¢ Source 3: 0.59 Ã— 20%                                         â”‚   â”‚
â”‚  â”‚  = 0.65 base score                                              â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  Multiplicative Bonuses:                                         â”‚   â”‚
â”‚  â”‚  Ã— 1.15  (3 sources bonus)                                      â”‚   â”‚
â”‚  â”‚  Ã— 1.12  (diverse: transcript + knowledge)                      â”‚   â”‚
â”‚  â”‚  Ã— 1.10  (has high confidence source > 0.5)                     â”‚   â”‚
â”‚  â”‚  = 0.92 final confidence                                        â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  Confidence Level: "Very High" (0.75+)                          â”‚   â”‚
â”‚  â”‚  Tags: [HIGH_CONFIDENCE], [TRANSCRIPT_GROUNDED],               â”‚   â”‚
â”‚  â”‚        [KNOWLEDGE_ENHANCED]                                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                 â†“                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 6.3 VALIDATION GATE                                              â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  validate_step() - Quality threshold                            â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  Requirements:                                                    â”‚   â”‚
â”‚  â”‚  âœ“ Confidence â‰¥ 0.4  (minimum quality bar)                      â”‚   â”‚
â”‚  â”‚  âœ“ Has transcript support (â‰¥1 transcript source)                â”‚   â”‚
â”‚  â”‚  âœ“ Has â‰¥1 source overall                                        â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  Decision:                                                        â”‚   â”‚
â”‚  â”‚  IF all requirements met:                                        â”‚   â”‚
â”‚  â”‚    â†’ [VALIDATED] â†’ Include in document                          â”‚   â”‚
â”‚  â”‚  ELSE:                                                            â”‚   â”‚
â”‚  â”‚    â†’ [REJECTED] â†’ Exclude from document                         â”‚   â”‚
â”‚  â”‚    â†’ Log warning with reason                                     â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  Result: X valid steps / N total steps                           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                           â”‚
â”‚  Final Validation:                                                        â”‚
â”‚  â€¢ IF valid_steps < 1: FAIL job (no empty documents)                    â”‚
â”‚  â€¢ ELSE: Proceed to document generation                                  â”‚
â”‚                                                                           â”‚
â”‚  Quality Metrics:                                                         â”‚
â”‚  â€¢ Average confidence: 0.68 (High)                                       â”‚
â”‚  â€¢ High confidence steps: 7/10 (â‰¥70%)                                    â”‚
â”‚  â€¢ Knowledge usage rate: 85% (2/2 sources cited)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â†“
Stage 7: ASSEMBLE DOCUMENT
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Document Generator: Professional Word Document (.docx)                  â”‚
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 7.1 Title Page                                                   â”‚   â”‚
â”‚  â”‚  â€¢ Brand name, subtitle, metadata                                â”‚   â”‚
â”‚  â”‚  â€¢ Generation date, version, author                              â”‚   â”‚
â”‚  â”‚  â€¢ Document information table                                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 7.2 Table of Contents                                            â”‚   â”‚
â”‚  â”‚  â€¢ Auto-generated from step titles                               â”‚   â”‚
â”‚  â”‚  â€¢ Can be replaced with Word TOC field for page numbers         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 7.3 Introduction                                                 â”‚   â”‚
â”‚  â”‚  â€¢ Document overview                                             â”‚   â”‚
â”‚  â”‚  â€¢ How to use this document                                      â”‚   â”‚
â”‚  â”‚  â€¢ Structure explanation                                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 7.4 Training Steps (Main Content)                                â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  For each validated step:                                        â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚  â”‚ Step N: [Title using exact transcript terminology]         â”‚ â”‚   â”‚
â”‚  â”‚  â”‚                                                             â”‚ â”‚   â”‚
â”‚  â”‚  â”‚ ğŸ“‹ Overview: [One sentence summary]                        â”‚ â”‚   â”‚
â”‚  â”‚  â”‚                                                             â”‚ â”‚   â”‚
â”‚  â”‚  â”‚ [2-3 sentences with knowledge-enhanced details]            â”‚ â”‚   â”‚
â”‚  â”‚  â”‚                                                             â”‚ â”‚   â”‚
â”‚  â”‚  â”‚ âœ… Key Actions:                                            â”‚ â”‚   â”‚
â”‚  â”‚  â”‚ 1. [Exact action from chunk]                               â”‚ â”‚   â”‚
â”‚  â”‚  â”‚ 2. [Exact action from chunk]                               â”‚ â”‚   â”‚
â”‚  â”‚  â”‚ 3. [Exact action from chunk]                               â”‚ â”‚   â”‚
â”‚  â”‚  â”‚                                                             â”‚ â”‚   â”‚
â”‚  â”‚  â”‚ Quality Indicator: High (68%) | Sources: transcript (3),   â”‚ â”‚   â”‚
â”‚  â”‚  â”‚                                          knowledge (2)      â”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 7.5 Source References (Appendix)                                 â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  For each step, list all sources:                               â”‚   â”‚
â”‚  â”‚  â€¢ Transcript excerpts (full sentences)                          â”‚   â”‚
â”‚  â”‚  â€¢ Knowledge source excerpts (with URLs)                         â”‚   â”‚
â”‚  â”‚  â€¢ Confidence score per source                                   â”‚   â”‚
â”‚  â”‚  â€¢ Source type icons: ğŸ“„ (transcript) ğŸŒ (knowledge)            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 7.6 Knowledge Sources Used                                       â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  List all fetched knowledge sources:                            â”‚   â”‚
â”‚  â”‚  â€¢ URL, title, type (web/PDF)                                   â”‚   â”‚
â”‚  â”‚  â€¢ Content preview (500 chars)                                   â”‚   â”‚
â”‚  â”‚  â€¢ Which steps cited this source                                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 7.7 Document Statistics                                          â”‚   â”‚
â”‚  â”‚                                                                   â”‚   â”‚
â”‚  â”‚  Processing metrics:                                             â”‚   â”‚
â”‚  â”‚  â€¢ Total steps: 10                                               â”‚   â”‚
â”‚  â”‚  â€¢ Average confidence: 68% (High)                                â”‚   â”‚
â”‚  â”‚  â€¢ High confidence steps: 7/10 (â‰¥70%)                            â”‚   â”‚
â”‚  â”‚  â€¢ Total source references: 45                                   â”‚   â”‚
â”‚  â”‚  â€¢ Processing time: 58.1 seconds                                 â”‚   â”‚
â”‚  â”‚  â€¢ Input tokens: 4,500                                           â”‚   â”‚
â”‚  â”‚  â€¢ Output tokens: 2,459                                          â”‚   â”‚
â”‚  â”‚  â€¢ Total tokens: 6,959                                           â”‚   â”‚
â”‚  â”‚  â€¢ Estimated cost: $0.0015                                       â”‚   â”‚
â”‚  â”‚  â€¢ Knowledge sources fetched: 2                                  â”‚   â”‚
â”‚  â”‚  â€¢ Knowledge sources cited: 2                                    â”‚   â”‚
â”‚  â”‚  â€¢ Knowledge usage rate: 100%                                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                           â”‚
â”‚  Output: Professional .docx document with:                               â”‚
â”‚  â€¢ ~15-20 pages (for 10 steps)                                           â”‚
â”‚  â€¢ Professional formatting (Calibri font, color-coded headings)          â”‚
â”‚  â€¢ Inline citations & quality indicators                                 â”‚
â”‚  â€¢ Complete source references                                            â”‚
â”‚  â€¢ Ready for distribution or editing in Word                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â†“
                           âœ… JOB COMPLETE
                    Document uploaded to Azure Blob Storage
                    User can download via frontend
```

---

## Stage-by-Stage Deep Dive

### Stage 1: LOAD & VALIDATE

**Purpose:** Accept user inputs and validate before processing

**Inputs:**
- Transcript file (.txt or .pdf, max 10MB)
- Configuration (tone, audience, target_steps, document_title)
- Knowledge URLs (optional, up to 10 URLs)

**Processing:**
1. Validate file format and size
2. Extract text from PDF if needed
3. Validate configuration parameters
4. Create job record in Cosmos DB
5. Upload transcript to Blob Storage

**Outputs:**
- Job ID (unique identifier)
- Initial job status: "queued"
- Validated configuration object

**Tags:** `[INIT]`, `[LOAD_TRANSCRIPT]`

**Error Handling:**
- Invalid file format â†’ Reject with clear error
- File too large â†’ Reject with size limit
- Missing config â†’ Use defaults (Professional, Technical Users, 8 steps)

---

### Stage 2: FETCH KNOWLEDGE

**Purpose:** Retrieve and extract content from external knowledge sources

**Inputs:**
- List of knowledge URLs from Stage 1

**Processing:**
1. **For each URL** (parallel processing):
   - Send HTTP request (30s timeout)
   - Detect content type (HTML, PDF, text)
   - Extract content:
     - HTML: BeautifulSoup (main content, remove nav/footer)
     - PDF: pypdf (extract text from all pages)
     - Text: Direct content
   - Clean whitespace, normalize
   - Truncate to 100,000 characters
   - Cache for 24 hours
2. Store metadata (URL, title, type, length)
3. Log success/failure per URL

**Outputs:**
- List of knowledge source dictionaries:
  ```python
  {
    "url": "https://learn.microsoft.com/...",
    "title": "Azure OpenAI Deployment Guide",
    "type": "web",
    "content": "When configuring...",  # up to 100k chars
    "error": None  # or error message if failed
  }
  ```

**Tags:** `[FETCH_KNOWLEDGE]`, `[FETCHED]`, `[ERROR]`, `[CACHED]`

**Performance:**
- Average fetch time: 2-5 seconds per URL
- Parallel fetching: All URLs fetched simultaneously
- Cache hit rate: ~70% (24-hour TTL)

**Error Handling:**
- URL timeout â†’ Log error, continue with other URLs
- Invalid URL â†’ Log error, continue
- Fetch failures don't block processing (graceful degradation)

---

### Stage 3: CLEAN & TOKENIZE

**Purpose:** Normalize transcript text and prepare for chunking

**Inputs:**
- Raw transcript text from Stage 1

**Processing:**
1. **Sentence tokenization** (NLTK)
   - Split on period, exclamation, question marks
   - Handle abbreviations (Dr., Mr., etc.)
   - Preserve sentence boundaries
2. **Text normalization**
   - Remove extra whitespace
   - Normalize punctuation
   - Fix common OCR artifacts (if from PDF)
3. **Build sentence catalog**
   - Index all sentences for source matching
   - Pre-calculate technical scores (for ranking)

**Outputs:**
- List of clean sentences
- Sentence catalog with indices
- Technical scores per sentence

**Tags:** `[CLEAN_TRANSCRIPT]`

**Performance:**
- Processing time: < 1 second (for 5-page transcript)
- Sentence count: Typically 50-200 sentences

---

### Stage 4: SEMANTIC CHUNKING

**Purpose:** Split transcript into N focused chunks (1 chunk â†’ 1 step)

**Inputs:**
- Clean sentence list from Stage 3
- target_steps (N) from configuration

**Processing:**
1. **Calculate chunk boundaries**
   - Total sentences Ã· target_steps = sentences per chunk
   - Ensure 6-12 sentences per chunk (adjust if needed)
2. **Split maintaining semantic continuity**
   - Don't split mid-topic
   - Look for natural boundaries (paragraph breaks, topic shifts)
3. **Balance chunk sizes**
   - No tiny chunks (< 6 sentences)
   - No huge chunks (> 12 sentences)
   - Redistribute if unbalanced

**Outputs:**
- List of N chunks (text strings)
- Average chunk size: 8-9 sentences
- Word count per chunk: 150-250 words

**Tags:** `[CHUNK_TRANSCRIPT]`

**Example:**
```
Input: 80 sentences, target_steps=10
â†’ 80 Ã· 10 = 8 sentences/chunk
â†’ Create 10 chunks with 8 sentences each
â†’ Adjust boundaries for semantic continuity
```

---

### Stage 5: GENERATE STEPS (The Core Loop)

**Purpose:** Generate ONE training step per chunk using LLM + knowledge

**Inputs (per chunk):**
- Transcript chunk (6-12 sentences)
- Knowledge sources (from Stage 2)
- Configuration (tone, audience, step index)

**Sub-Stages:**

#### 5.1 Semantic Search
- **Model:** sentence-transformers (all-MiniLM-L6-v2)
- **Process:**
  1. Encode chunk â†’ embedding vector (384 dims)
  2. Split each knowledge source into 500-char overlapping excerpts
  3. Encode each excerpt â†’ embedding vector
  4. Calculate cosine similarity: chunk â†” excerpt
  5. Filter excerpts with similarity < 0.1
  6. Sort by similarity (descending)
  7. Select top 5 excerpts overall

- **Output:** Top 5 relevant excerpts with scores
  ```python
  [
    {
      "source_title": "Azure Deployment Guide",
      "source_url": "https://...",
      "excerpt": "When configuring deployment capacity...",
      "relevance_score": 0.87
    },
    ...
  ]
  ```

#### 5.2 Prompt Construction
- **Template:** Chunk-focused prompt
- **Components:**
  - System instructions (grounding rules)
  - Transcript chunk (quoted)
  - Top 5 knowledge excerpts (with scores)
  - DO/DON'T instructions
  - Output format specification

#### 5.3 LLM Generation
- **Model:** Azure OpenAI (gpt-4o) or OpenAI (gpt-4o-mini fallback)
- **Parameters:**
  - Temperature: 0.2 (focused, consistent)
  - Max tokens: 1000
  - Top-p: 0.85
  - Timeout: 60s

- **Output:** Single training step (JSON)
  ```python
  {
    "title": "Configure Deployment Settings",
    "summary": "Navigate to Deployments section...",
    "details": "In the Azure Portal, access...",
    "actions": ["Navigate to...", "Click Create..."]
  }
  ```

**Performance (per chunk):**
- Semantic search: ~1 second
- Prompt construction: < 0.1 second
- LLM call: ~3-5 seconds
- Total: ~4-6 seconds per step

**Total for 10 steps:** 40-60 seconds

**Tags:** `[GENERATE_STEPS]`, `[SEMANTIC_MATCH]`, `[HIGH_RELEVANCE]`

**Error Handling:**
- LLM timeout â†’ Retry once, then skip chunk
- Invalid response â†’ Skip chunk, log error
- Continue with remaining chunks (graceful degradation)

---

### Stage 6: VALIDATE & SCORE (Quality Gate)

**Purpose:** Calculate confidence and validate each step meets quality threshold

**Inputs (per step):**
- Generated step from Stage 5
- Transcript sentences (from Stage 3)
- Knowledge sources (from Stage 2)

**Sub-Stages:**

#### 6.1 Source Matching
- **Process:**
  1. Search transcript for sentences matching step content
  2. Calculate hybrid similarity:
     - 50% word overlap (Jaccard: |Aâˆ©B| / |AâˆªB|)
     - 50% semantic similarity (sentence-transformers)
  3. Require minimum 3 matching words
  4. Require similarity â‰¥ 0.15
  5. Select top 5 transcript sources
  6. Match knowledge sources (if cited in step)

- **Output:** List of sources per step
  ```python
  [
    SourceReference(
      type="transcript",
      excerpt="Navigate to Deployments section...",
      sentence_index=42,
      confidence=0.68
    ),
    SourceReference(
      type="knowledge",
      excerpt="Microsoft recommends 10K TPM...",
      confidence=0.87
    )
  ]
  ```

#### 6.2 Confidence Calculation
- **Formula:** Multi-factor multiplicative scoring
  1. **Base score:** Weighted average of top 3 sources
     - Source 1: weight 50%
     - Source 2: weight 30%
     - Source 3: weight 20%
  2. **Multiplicative bonuses:**
     - Ã—1.25 for 4+ sources
     - Ã—1.15 for 3 sources
     - Ã—1.08 for 2 sources
     - Ã—1.12 for diverse sources (transcript + knowledge)
     - Ã—1.10 for high confidence source (>0.5)
  3. **Clamp:** [0.0, 1.0]

- **Confidence levels:**
  - Very High: 0.75+ (Excellent grounding)
  - High: 0.55-0.74 (Strong grounding)
  - Medium: 0.35-0.54 (Acceptable)
  - Low: 0.20-0.34 (Weak)
  - Very Low: <0.20 (Rejected)

#### 6.3 Validation Gate
- **Requirements:**
  1. Confidence â‰¥ 0.4
  2. Has â‰¥1 transcript source
  3. Has â‰¥1 source overall

- **Decision:**
  - **PASS:** All requirements met â†’ `[VALIDATED]`
  - **FAIL:** Any requirement not met â†’ `[REJECTED]`

- **Final gate:**
  - IF valid_steps < 1 â†’ FAIL entire job
  - ELSE â†’ Proceed to Stage 7

**Performance:**
- Source matching: ~0.5 seconds per step
- Confidence calculation: < 0.1 second
- Total: ~0.6 seconds per step Ã— 10 = 6 seconds

**Tags:** `[BUILD_SOURCES]`, `[VALIDATE_STEPS]`, `[VALIDATED]`, `[REJECTED]`

**Quality Metrics:**
- Average confidence: 55-65% (typical)
- High confidence rate: 50-70% of steps
- Rejection rate: 0-10% of steps
- Knowledge usage: 70-90% of sources cited

---

### Stage 7: ASSEMBLE DOCUMENT

**Purpose:** Create professional Word document with all validated steps

**Inputs:**
- Valid steps (from Stage 6)
- Step sources (from Stage 6)
- Knowledge sources (from Stage 2)
- Configuration (title, metadata)
- Statistics (tokens, time, confidence)

**Processing:**
1. **Initialize Document** (python-docx)
   - Set fonts (Calibri 11pt)
   - Configure heading styles
   - Set page margins

2. **Add Sections** (in order):
   - Title page (brand, metadata)
   - Table of contents (manual, can be replaced)
   - Introduction (overview, how-to-use)
   - Training steps (main content)
   - Source references (appendix)
   - Knowledge sources (appendix)
   - Document statistics (metrics)

3. **Format Each Step:**
   ```
   Step N: [Title]

   ğŸ“‹ Overview: [Summary]

   [Details with knowledge enhancements]

   âœ… Key Actions:
   1. [Action]
   2. [Action]

   Quality Indicator: High (68%) | Sources: transcript (3), knowledge (2)
   ```

4. **Add Source References:**
   - Full transcript excerpts (quoted)
   - Knowledge source excerpts (with URLs)
   - Confidence scores per source
   - Icons: ğŸ“„ (transcript) ğŸŒ (knowledge)

5. **Add Statistics Table:**
   - Total steps, confidence, tokens, cost
   - Knowledge usage metrics
   - Processing time

**Outputs:**
- Professional .docx file (~15-20 pages for 10 steps)
- Upload to Azure Blob Storage
- Return download URL to user

**Performance:**
- Document generation: ~5-10 seconds
- File size: ~50-150 KB

**Tags:** `[CREATE_DOCUMENT]`, `[COMPLETE]`

---

## Processing Tags Reference

### Status Tags
| Tag | Meaning |
|-----|---------|
| `[INIT]` | Pipeline initialized |
| `[LOAD_TRANSCRIPT]` | Loading transcript file |
| `[FETCH_KNOWLEDGE]` | Fetching knowledge URLs |
| `[CLEAN_TRANSCRIPT]` | Cleaning and normalizing text |
| `[CHUNK_TRANSCRIPT]` | Splitting into chunks |
| `[GENERATE_STEPS]` | Generating steps from chunks |
| `[BUILD_SOURCES]` | Finding source references |
| `[VALIDATE_STEPS]` | Validating step quality |
| `[CREATE_DOCUMENT]` | Assembling Word document |
| `[COMPLETE]` | Processing finished successfully |
| `[ERROR]` | Fatal error occurred |

### Knowledge Tags
| Tag | Meaning |
|-----|---------|
| `[FETCHED]` | Successfully fetched from URL |
| `[CACHED]` | Using cached content (< 24 hours old) |
| `[SEMANTIC_MATCH]` | Using semantic similarity |
| `[KEYWORD_MATCH]` | Using keyword matching (fallback) |
| `[HIGH_RELEVANCE]` | Excerpt score â‰¥ 0.5 |
| `[MEDIUM_RELEVANCE]` | Excerpt score 0.2-0.49 |
| `[LOW_RELEVANCE]` | Excerpt score 0.1-0.19 |
| `[FILTERED]` | Excerpt below threshold (< 0.1) |

### Quality Tags
| Tag | Meaning |
|-----|---------|
| `[HIGH_CONFIDENCE]` | Step confidence â‰¥ 0.7 |
| `[MEDIUM_CONFIDENCE]` | Step confidence 0.4-0.69 |
| `[LOW_CONFIDENCE]` | Step confidence < 0.4 (rejected) |
| `[TRANSCRIPT_GROUNDED]` | Has transcript sources |
| `[KNOWLEDGE_ENHANCED]` | Has knowledge sources |
| `[VALIDATED]` | Passed all quality gates |
| `[REJECTED]` | Failed validation |

---

## Performance Metrics (10-Step Document)

| Metric | Value |
|--------|-------|
| **Total Processing Time** | 45-65 seconds |
| Stage 1 (Load) | < 1 second |
| Stage 2 (Fetch Knowledge) | 2-5 seconds |
| Stage 3 (Clean) | < 1 second |
| Stage 4 (Chunk) | < 1 second |
| Stage 5 (Generate) | 40-60 seconds |
| Stage 6 (Validate) | 5-8 seconds |
| Stage 7 (Assemble) | 5-10 seconds |
| **Total Tokens** | 6,000-8,000 |
| Input tokens/step | ~450 |
| Output tokens/step | ~200 |
| **Estimated Cost** | $0.0015-0.0025 |
| GPT-4o ($0.15/1M in, $0.60/1M out) | - |
| **Average Confidence** | 55-65% (High) |
| **Knowledge Usage** | 70-90% |

---

## Key Innovations

### 1. Chunk-Level Knowledge Matching
**Traditional RAG:**
- Sends entire knowledge base to every query
- Same context for all steps
- High token usage

**ScriptToDoc Pipeline:**
- Semantic search finds top 5 excerpts per chunk
- Different context per step
- 60% token savings

### 2. Iterative Quality Loop
**Per-Chunk Process:**
```
Chunk â†’ Semantic Search â†’ LLM Generate â†’ Source Match â†’ Confidence Score â†’ Validate
  â†“                                                                             â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  IF confidence â‰¥ 0.4: PASS â†’ Include in document
  IF confidence < 0.4: FAIL â†’ Reject (log warning)
```

### 3. Multiplicative Confidence Scoring
- Prevents low-quality steps from passing with bonuses
- Rewards truly high-quality steps
- Text-only (visual support excluded)

### 4. Graceful Error Recovery
- Knowledge fetch failures don't block processing
- LLM failures skip chunk, continue others
- Validates â‰¥1 step generated (no empty documents)

---

## Error Handling Strategy

| Error Type | Stage | Recovery |
|------------|-------|----------|
| Invalid file | Stage 1 | Reject with clear message |
| Knowledge URL timeout | Stage 2 | Log error, continue with other URLs |
| LLM timeout | Stage 5 | Retry once, then skip chunk |
| All chunks failed | Stage 5 | FAIL job with root cause |
| All steps rejected | Stage 6 | FAIL job with detailed reason |
| Document generation error | Stage 7 | FAIL job, preserve intermediate data |

**Philosophy:** Fail fast with clear errors, but continue when possible (graceful degradation)

---

## Monitoring & Debugging

### Backend Logs (by Stage)

**Stage 2 (Fetch):**
```
INFO - Fetching knowledge from 2 URLs
INFO - Fetched https://learn.microsoft.com/... (15234 chars)
INFO - Fetched https://docs.azure.com/... (22156 chars)
INFO - Successfully fetched 2/2 knowledge sources
```

**Stage 4 (Chunk):**
```
INFO - Created 10 chunks (avg 8.3 sentences/chunk)
```

**Stage 5 (Generate):**
```
INFO - Generating step 1/10 from chunk (542 chars)
INFO - [SEMANTIC_MATCH] Found 5 relevant excerpts (max relevance: 0.87)
INFO - Generated step 1: "Configure Azure OpenAI Deployment"
```

**Stage 6 (Validate):**
```
INFO - Step 1: Confidence 0.68 (High), 5 sources, valid: True
INFO - Step 2: Confidence 0.72 (High), 4 sources, valid: True
...
INFO - Validated: 10/10 steps passed
```

**Stage 7 (Assemble):**
```
INFO - Creating Word document with 10 steps
INFO - Document saved to: output/training_document.docx
```

### Frontend Progress

```
â³ Loading transcript... (5%)
â³ Fetching knowledge sources... (20%)
â³ Cleaning transcript... (30%)
â³ Chunking transcript... (40%)
â³ Generating steps... (60%)
   â””â”€ Generating step 3 of 10
â³ Validating steps... (85%)
â³ Creating document... (95%)
âœ… Document generated successfully! (100%)
```

---

## Summary: 7-Stage Pipeline

The ScriptToDoc agent is **not just a two-phase system** - it's a sophisticated **7-stage pipeline** where each stage builds on the previous:

1. **LOAD & VALIDATE** - Accept and verify inputs âœ‹ (User control)
2. **FETCH KNOWLEDGE** - Retrieve external sources (Parallel, cached)
3. **CLEAN & TOKENIZE** - Normalize transcript (NLTK, indexing)
4. **SEMANTIC CHUNKING** - Split into focused chunks (N chunks â†’ N steps)
5. **GENERATE STEPS** - **Core iterative loop** (Search â†’ Generate â†’ per chunk) ğŸ”„
6. **VALIDATE & SCORE** - **Quality gate** (Match â†’ Score â†’ Validate) ğŸ”
7. **ASSEMBLE DOCUMENT** - Professional output (Word .docx, 15-20 pages)

**The result:** High-quality training documents that are grounded in transcripts, enhanced with expert knowledge, and validated for confidenceâ€”all automatically in 45-65 seconds.
