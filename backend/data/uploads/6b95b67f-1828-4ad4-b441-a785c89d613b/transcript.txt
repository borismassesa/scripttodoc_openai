Pattern Ingestion Prompting-20260204_110249-Meeting RecordingFebruary 4, 2026, 6:02PM24m 50sKelly Jones (Revel) started transcriptionAlan Zhang   0:03That's a lot. Yep, let's just jump right into it. It should be pretty quick and I hope it works. OK, share my screen window.Patricia Dorfman (Revel)   0:11Thanks.Thanks.Alan Zhang   0:22This one.Uh, can you see like engineering at the speed of light?   0:29Yes.Patricia Dorfman (Revel)   0:29Yes.Alan Zhang   0:31OK, cool. So this is kind of like.Um, this is like kind of our demo page that we use for like sales and things like that. So there's like a bunch of patterns. Um.Like these.Text things, text blocks, this hero banner, feature grids, things like that. And like we're going to want to migrate things to this page. So what we do is when we go back into design systems, like this part is still the same, so.Demo integrate suggestion.So we create design systems and basically we're using them as like templates essentially. So if I this is my template page, I'm gonna take the URL from AEM. So this is kind of in our sandbox environment.Put it in here similar to like how we ingest patterns today. We have like that little like page to ingest from and then it's we gotta make sure that we'll have we're connected to like an instance. So usually you'll say like AM Microsoft prod or something.Um. And then just hit create and then this goes into like pretty much the same workflow as um.As like all the other tickets that we see. So it's like very agentic and we'll have the agent scan for artifacts, scan for patterns and then determine what there is on the page. So we'll have to wait a little bit, but I think this is a pretty lightweight template, so.Um shouldn't be too bad.Kelly Jones (Revel)   2:12So the agent's reading each component on the source URL and like mapping it over for us and building the the patterns into Gradio.Alan Zhang   2:25Um, yeah. So like similarly to old pattern ingestion like.Sorry.Like the old pattern ingestion, it was just like you put in a URL and it like just like spits out like a bunch of patterns. It's like a very similar algorithm. I think there are some improvement. There are like some base improvements into this algorithm, but it's still very similar the.The the the way that this is better from the previous experience is because previously we only had one extra button which was to break down the pattern into smaller patterns. So oftentimes the secondary nav would like consume the entire page cuz everything's underneath the secondary NAV and the agent thinks.Oh, the pattern is called secondary NAV and everything in here needs to be filled. In reality the patterns are like what's underneath. So and then when you hit breakdown into smaller components in the previous UI, oftentimes it would break it down way too small. So it would like break out to like all the feature grids, all the article chat.And things, but it also break down like each hyperlink or like each anchor link on the page to its own component. And it like overall was like a very long procedure to do that because like you would have to break it and you would have like no updates until like it's actually broken.Um, this is taking a little longer than I expected.OK, I'm gonna highlight some other things while this thing is running. So it's really hard to actually get back to this page. I think that's just like a that's like a UI improvement that we're working on figuring out how to do. So I like, I really recommend just like renaming.This thread to like something identifiable to say like Alan demo. And then since you all are admins in our workspace, you'll see this pattern ingestion folder. Basically the way it works is that like every single pattern ingestion has to live in some workspace, so we.Have this private workspace to do our ingestion in, but then like you can access it through this pattern ingestion workspace 'cause otherwise if you go here you see if I go to.Where's even my design system?Huh.Oh, there it is. If you click into here, you won't be able to find it. And that's just like a UI improvement that we have to do. But yeah, pattern adjusting, you can go back here to see when it's done. So here it's like, oh, it's ready for review. I can see pattern detection clinic 9 patterns for the page.So you can review and check the panel boundaries before I persist them. So persisting is like kind of what we're calling like saving it to the actual pattern. So you can go to our artifact, click it.Sorry, gotta move my little teams chat thing and right now we see like every pattern is like selected in the live preview. So like here like we can see like brand logos, text scroll image.All the way down, this is all one pattern and then this is another planet pattern, full bleed text image, things like that. So we can like persist them, but like say like something didn't look right like this hero I don't really like.One thing we can do is we cover to the name and we can actually like cross it out. Oh, brand logos. Let's say brand logos wasn't right. I cross it out and then like now it's saying this isn't a pattern, so we can still persist it. So we can persist all eight that we saw.So I'm going to hit this persist button and it should give me a new prompt. Please persist the patterns to the design system so it'll start saving those patterns and while it's doing that, another thing we can do is we can select additional patterns so.It's saving those A patterns, but like before it was this whole thing. But let's say like each maybe like each card should be its own pattern. So I like I might select this.OK, never mind. Like I can like say like it did an injustice in the beginning. You can like go in and select it as another pattern manually and then you can hit done and then you'll see that it's in green because it hasn't been persisted yet or.No, no, it's in green because we manually selected it. So yeah, it'll save this a patterns first. It's a little slow right now. I think it's still because.We detect the patterns and then we try to do the classification after and the classification is kind of like the harder part. So yeah, that might take a while, but after this, like you can select another one and you can persist it again. Yeah, we're getting an error. I ran into this on like my local development space and.I think we have a fix out for it this morning. I gotta check my code reviews and then yeah.Oh, network area network error.OK, yeah, probably an issue. Like we're we're gonna figure this out like soon. I believe it should work in like other people's local development errors area. So I will double check that with the engineering team.But yeah, basically like the main improvement is like this UI on the right side to select to actually like select the patterns you want. So hopefully this allows us to like more accurate, really select the.Accurately select the things, the patterns that the blades slash patterns that we actually want.So another thing is like when I was hitting select, you notice that like some logos you can't select it. And that's because one thing we're doing is like if I go into inspect, like we're only ingesting, we're only thinking things are patterns. Oops, sorry.If they have like ACQ like the CQ label on it, CQ data path. So like here like this brand logo section should have like this CQ associated with it, yeah.I think it's, I think it's gonna be this one, the sibling relationship. Yep, brand logos, container slash brand logo. So we need this like CQ container versus something like.This brand logo doesn't have any CQ containers associated with it, so that's like why we can't ingest it as a pattern. So that's something to keep in mind when we're creating like new template pages is that we got to make sure like what's actually a blade is actually labeled as like a container in AEM.Um, yeah, that's like the other thing I wanted to highlight, so.That's kind of it. I'm sorry it didn't really work immediately, but this is just the general UI of the workflow. Are there any questions?Kelly Jones (Revel)   9:56Help.Alan Zhang   10:08Yep.So this 111 thing was ingested I think like last week. So you can see like oh they this UI is still the same like and like all this like sidebar shooting out all this editable fields. These are all the same.Patricia Dorfman (Revel)   10:19OK, great.OK. Were there any changes to how values work or is that still the same?Alan Zhang   10:31It's still the same. The UI has changed to be like well to be like kind of this editable field. So previously it was high and low priority. Basically we've like reflected the UI to actually be what the agent would look at it. Basically it's saying high priority things are editable.Meaning that it could supply its own values to things like the image, the title, the alt text, all these things are like pretty much like always gonna be true. Like the agent should supply the information and things that were previously low priority are now just like kind of uneditable. So kind of like things like the button.Link target like all these things that you want to stay the same for every single time this pattern is used. Previously it was low priority, now it's not editable but like underlying it no function difference.Patricia Dorfman (Revel)   11:26Great.Alan Zhang   11:32But yes.Kelly Jones (Revel)   11:34Um.Is this gonna be different for AEM stuff or is it gonna be pretty much universal for all of you guys's clients? And do we need to test it with AEM better or are you pretty confident that it should work with AEM once it's live again?Alan Zhang   11:56I was pretty confident with the pattern injection ingestion when I was testing against staging yesterday and also like this sandbox environment is an AEM instance like it's our personal AEM. So yeah.Kelly Jones (Revel)   12:07OK.OK.OK.Alan Zhang   12:17The other thing is that I think we'll have a little better. I I actually just noticed this. I know we're really bad with release notes, but there's like this draft status and release status. I believe this thing actually works. So if we're like ingesting patterns and like we're editing it, you can keep it in draft phase.So any like ongoing migration work won't use the that pattern until it's released. So another control button that you can use.And then, yeah, I know like.I know like a lot of this was like kind of sorry. A lot of this was done by like me and Patricia manually and like I think like Andrew and Kelly, you might have to start doing it, but like feel free to like ask me any questions there's.Tools in the back end I can look at to see like what the actual underlying thing was ingested or like if there are errors during ingestion. But yeah, I'll be available to help out with this workflow, especially since it's new.Kelly Jones (Revel)   13:26Are there any technical things with prompting that we need to do, or is it just kind of natural language? Just ask it to do what you think?Alan Zhang   13:36Yeah, I think it's natural language as you think. Like honestly, like like you saw how like when I hit this like button, it just prompted the agent with this like.Normal text and even like this initial prompt is like from a template. I yeah, natural language prompting has worked for me with this agent. So this is a completely different agent. Also like previously we were using AM authoring. This is just a pattern detection agent, so it's like completely separate, which is nice.So it won't have a lot of the same like context bloat like we've been dealing with. So yeah, extending the conversation. I've had pretty good success with doing this here. It's like.If you deselect the hero.Let's see if this works. Like it works fine. Honestly, the biggest thing though is like, I really like the buttons. I think the buttons are like, probably gonna be the big improvement here. Yeah, Steven.Kelly Jones (Revel)   14:43It looks like.Steven Driggs (Revel)   14:44I've got a quick question. Yeah, I'm ignorant to the platform and I'm I'm here listening to the fly and I'm trying to catch up on things and learn and and get into the swing of things. Saying natural language query or natural language prompting, that's really, really vague. Can we can we dive in a little bit more into like?Alan Zhang   14:53Sure.Steven Driggs (Revel)   15:03What frameworks prompting works best if you know guidance because every model operates differently and just love to hear like what it what have you tried and what works best? Is there like is it more receptive to frameworks?From like anthropic versus ChatGPT or whatnot, I just also have realized in the past that natural language prompting can mean just so many different things. So just to make sure I'm on the same page, any thoughts there?Alan Zhang   15:35Yeah, for sure. I think like when me and Kelly talk about it, at least how I interpret it as natural language is like kind of like talking with the agent, not giving it a lot of structure or context. A lot of the prompts we have been doing with the authoring agent have been extremely like structured given like an objective.Uh, steps to take and steps to follow. Um, but I think Kelly, if you want to speak a little bit more on that, um, I know you had have a meeting to like kind of share what you've learned with everyone at Revel, but I'm not sure of the state of that.Kelly Jones (Revel)   16:09Oh yeah, that got postponed from last week. We really need to test like more to get it.In detail. And this is a new agent, Steve. So this isn't really, um, the main work we're doing with prompting. This is just something new that we, uh, wanna be aware of to know if we need to add more structure to the prompt. And that's why I was kind of asking Alan like if it's just.A quick natural language thing like that, or if it's gonna be needed to be structured. But Andrew and Patricia are probably gonna be running this more than anyone, so we should probably let them ask any of the technical questions with.If prompting is not going to be a big issue here.Patricia Dorfman (Revel)   16:57Yeah, I guess we won't know until we can try it.Alan Zhang   17:01Yeah, no, for sure I.I'm with that as well. And like another thing is this like the Microsoft Blades are like so much bigger than these components. Like I I suspect that the Microsoft Blade will take a while to ingest and there'll be a lot of like manual selection.Um.Yeah.Kelly Jones (Revel)   17:25That that does raise a little bit of a flag for me, Alan, when you said that. Um.Alan Zhang   17:26Like I've tested it locally and it did.Mhm.Kelly Jones (Revel)   17:33If the blades are bigger and the agent's gonna have to use more context, then what are our editing capabilities with this new agent to make sure like the patterns get done right? Cause if the outputs aren't gonna be like really good quality when we ask it to ingest the pattern, then how?Can like Andrew and Patricia like edit it using this agent to make it good for when we, uh, send it off to the next part of the process?Alan Zhang   18:02Yeah, that's what I was saying is like, I don't think you should really use the agent that much. Like you should really view this as like kind of an improvement off what was existing. Like now you just have a UI and like these buttons to take a look at like what patterns are existed and are ingested, which ones did the agent select and like which ones are manually.Selected like I would really view this as like kind of just like a UI improvement on uh pattern ingestion.So like, yeah, to Kelly, your point, I feel like process wise, like I think more of the UI is like what's key here.Kelly Jones (Revel)   18:48Sounds good. Um.Do you have any questions, Andrew or Patricia?Patricia Dorfman (Revel)   18:57No, I think. I think I won't have questions until I can test.Alan Zhang   19:02Yeah, understood.And then I think everyone on this call is kind of like was probably contacted yesterday, at least I I asked in one of our channels. But I think like one of the issues that's like preventing us from like testing faster is the discrepancy between the AEM prod and AEM staging.So I've asked I think Steven, I think you were in that call like to push like Akshay and that team to like kind of start the sync and then like syncing it and they want like a subset of pages to sync. So if there's like any patterns that like like the SEO template, the PPP template, the solution.Steven Driggs (Revel)   19:34Yeah.Alan Zhang   19:46But like all these templates should definitely be synced over to staging so we can like test in staging with the most up to date templates that we have.So we need to come up with that list as well.Mhm.Yeah.Steven Driggs (Revel)   20:14That we're actively trying to pursue.Alan Zhang   20:19Yeah, for sure.Kelly Jones (Revel)   20:19One ask Alan, I have for this if you could provide like a five step or six step thing like workflow to just hand off to us saying like go here to patterns, go do this like so that we can leave Andrew and Patricia with like some type of document that gives them.Like the steps they need to do to follow this new process and kind of like the tools they have now based on the new UI. I don't know if you can provide that, but that would be helpful.Alan Zhang   20:47Yeah, for sure.Yeah, I can do that. And I think things that like I did was like renaming this thread and like knowing to go to like pattern ingestion in the left sidebar. Yeah, I think that should definitely be captured in something. So yeah.Kelly Jones (Revel)   21:00Thank you.Steven Driggs (Revel)   21:01Hey, um.Alan, can you just say the steps on the recording again? I actually, I don't want to derail you from doing it on your side, but I might also have a tool that can help us here and I can just look at the transcript. So if you just say like the steps in order.Alan Zhang   21:09Oh.Kelly Jones (Revel)   21:14Oh yeah.Alan Zhang   21:15For sure.Steven Driggs (Revel)   21:19I can use that. We'll still want you to put something together, but I might be able to help as well.Alan Zhang   21:25Yeah, for sure. So first step, go to greatdeal.com. Second step, open up like the AEM page that you want to be ingesting from. Um.Just make sure you have that AEM link handy so we can go into design systems, either create a new design system or going to an existing one and then you'll be prompted for that AEM URL so we can go ahead, copy and paste it in.And then you'll wait for this green check mark to see you're connected to AEM, hit get started and that will kick off the ingestion process and it might take a while. So if any time you need to come back to it, a way to easily remember what it's called is to go up to the title of the thread.Give it an identifiable name, so I'm gonna call it Alan Test 2. Save it and then in your private workspaces in the left sidebar you should have pattern ingestion as one of the workspaces and if you go in you should be able to see or.Name in that folder. So if you go in, you can kind of click and see how the state of the agent is going. So once the agent finishes, you see that it's ready for review. You can step in and go to the right preview panel.And hit the AEM artifact and that will allow you to see a preview of the page and also like in outlines what the agent has selected and you can use the buttons in the little floating.We call this widget to help select banners and persist it so you can select more manually that the agent might have missed. You can deselect them by hovering over the name and hitting the small X that it changes to.And then to save them all, make sure you hit persist and the persist will prompt the agent to save all the patterns into text.So that should be it.Steven Driggs (Revel)   23:35Thank you very much. Appreciate that.Alan Zhang   23:37Yep, absolutely.Uh, any other questions?I know, I know we're still blocked on AM prod, so I understand that this is only so helpful right now.Kelly Jones (Revel)   23:56Um.I think we'll need to like test it with some more of the complicated blades that we have to really get to know this new approach and see if it works. So we might need to like.Alan Zhang   24:09Mhm.Kelly Jones (Revel)   24:13Tell AV and other people like that could be a potential blocker if like the outputs aren't coming out as we want them. So just a flag that we can notate.Alan Zhang   24:22Mhm.Sure.Patricia Dorfman (Revel)   24:30All right. Well, thank you so much. Yeah, thank you so much, Alan. We're almost up on time. So if there's nothing else, I think we can end early.Alan Zhang   24:30Yeah, sounds good.Patricia Dorfman (Revel)   24:42Sound good? All right. Well, thanks. Bye, bye.Kelly Jones (Revel)   24:43Sounds good. Thanks everyone. Bye.Kelly Jones (Revel) stopped transcription